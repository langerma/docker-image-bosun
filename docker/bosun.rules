###################
# my bosun config #
###################

##########
# Macros #
##########

# for series that should not drop
macro anomaly {
    $g_hist = band($q_metric, $q_duration, $q_period, $q_lookback)
    $s_hist_dev = dev($g_hist)
    $s_hist_median = percentile($g_hist, .5)
    $s_current_median = percentile(q($q_metric, $q_duration, ""), .5)
    $s_median_diff = $s_current_median - $s_hist_median
    $graph = over($q_metric, $q_duration, $q_period, $q_lookback)
    warn = $s_current_median > ($s_hist_median + $s_hist_dev*2) && abs($s_median_diff) > $g_std_warn
    crit = $s_current_median > ($s_hist_median + $s_hist_dev*2) && abs($s_median_diff) > $g_std_crit
}

# for series that should not rise
macro anomaly.inverted {
    $g_hist = band($q_metric, $q_duration, $q_period, $q_lookback)
    $s_hist_dev = dev($g_hist)
    $s_hist_median = percentile($g_hist, .5)
    $s_current_median = percentile(q($q_metric, $q_duration, ""), .5)
    $s_median_diff = $s_current_median - $s_hist_median
    $graph = over($q_metric, $q_duration, $q_period, $q_lookback)
    warn = $s_current_median < ($s_hist_median + $s_hist_dev*2) && abs($s_median_diff) > $g_std_warn
    crit = $s_current_median < ($s_hist_median + $s_hist_dev*2) && abs($s_median_diff) > $g_std_crit
}

### NOTE: currently use with caution, it can generate some load
macro anomaly.erratic {
    $g_hist = band($q_metric, $q_duration, $q_period, $q_lookback)
    $s_hist_dev = dev($g_hist)
    $s_hist_median = percentile($g_hist, .5)
    $s_current_median = percentile(q($q_metric, $q_duration, ""), .5)
    $s_median_diff = $s_current_median - $s_hist_median
    $s_erratic = q($q_erratic_metric, $q_erratic_period, "")
    $s_erratic_dev = (dev($s_erratic) * $s_hist_median) / ( ($s_hist_dev * median($s_erratic)) + 0.01)
    $s_median_diff_dev = ($s_current_median - $s_hist_median)/($s_hist_dev+0.01)
    $s_median_bad = $s_median_diff_dev < $g_min_med_diff
    $s_median_issues = sum(t($s_median_bad,""))
    warn = ($s_current_median > ($s_hist_median + $s_hist_dev*2) && abs($s_median_diff) > $g_std_warn) || ($s_erratic_dev > $g_max_erratic_warn && $s_median_issues > ($g_max_num_issues_crit / 2))
    crit = ($s_current_median > ($s_hist_median + $s_hist_dev*2) && abs($s_median_diff) > $g_std_crit) || ($s_erratic_dev > $g_max_erratic_crit && $s_median_issues > $g_max_num_issues_crit)
}

#############
# templates #
#############

template mattermost {
  MattermostBody = `payload={"username": "bosun-bot", "text": "{{.Subject}} <{{.Incident}}|view in bosun>"}`
}

notification mattermost {
  post = http://gevispoc.eb.lan.at/hooks/hh4a9kjpepri383j4s7pn7f9zw
  #select slack body template
  bodyTemplate = MattermostBody
}

notification default {
    email   = langer.markus@gmail.com
    print   = true
    #next    = default
    #timeout = 1d
}

template ut {
    subject = {{.Name}}: {{.Group | len}} unknown alerts
        body = `
            <p>Time: {{.Time}}
            <p>Name: {{.Name}}
            <p>Alerts:
            {{range .Group}}
            <br>{{.}}
    {{end}}`
}

unknownTemplate = ut

template generic {
        body = `<a href="{{.Ack}}">Acknowledge alert</a>
        <p>Alert definition:
        <p>Name: {{.Alert.Name}}
        <p>Crit: {{.Alert.Crit}}
        <p>Tags
        <table>
                {{range $k, $v := .Group}}
                        {{if eq $k "host"}}
                                <tr><td>{{$k}}</td><td><a href="{{$.HostView $v}}">{{$v}}</a></td></tr>
                        {{else}}
                                <tr><td>{{$k}}</td><td>{{$v}}</td></tr>
                        {{end}}
                {{end}}
        </table>

        <p>Computation
        <table>
                {{range .Computations}}
                        <tr><td>{{.Text}}</td><td>{{.Value}}</td></tr>
                {{end}}
        </table>
        </br>
        {{.Graph .Alert.Vars.metric}}`
        subject = {{.Last.Status}}: {{.Alert.Name}}: {{.Eval .Alert.Vars.q}} on {{.Group.host}}
}

template weblog.rtm {
        body = `<a href="{{.Ack}}">Acknowledge alert</a>
        <p>Alert definition:
        <p>Name: {{.Alert.Name}}
        <p>Crit: {{.Alert.Crit}}
        <p>Tags
        <table>
                {{range $k, $v := .Group}}
                        {{if eq $k "host"}}
                                <tr><td>{{$k}} :</td><td><a href="{{$.HostView $v}}">{{$v}}</a></td></tr>
                        {{else}}
                                <tr><td>{{$k}} :</td><td>{{$v}}</td></tr>
                        {{end}}
                {{end}}
        </table>
        <br />
        <table>
                        <tr><th>Expression</th><th>Value</th></tr>
                {{range .Computations}}
                        <tr><td>{{.Text}} :</td><td>{{.Value}}</td></tr>
                {{end}}
        </table>
        </br>`
        subject = {{.Last.Status}}: {{.Alert.Name}}: {{.Eval .Alert.Vars.p50}} on {{index .Group "ident.keyword"}}
}

template load {
        body = `<a href="{{.Ack}}">Acknowledge alert</a>
        <p>Alert definition:
        <p>Name: {{.Alert.Name}}
        <p>Crit: {{.Alert.Crit}}
        <p>Tags
        <table>
                {{range $k, $v := .Group}}
                        {{if eq $k "host"}}
                                <tr><td>{{$k}}</td><td><a href="{{$.HostView $v}}">{{$v}}</a></td></tr>
                        {{else}}
                                <tr><td>{{$k}}</td><td>{{$v}}</td></tr>
                        {{end}}
                {{end}}
        </table>

        <p>Computation
        <table>
                        <tr><th>Expression :</th><th>Value :</th></tr>
                {{range .Computations}}
                        <tr><td>{{.Text}}</td><td>{{.Value}}</td></tr>
                {{end}}
        </table>
        </br>
        {{.Graph .Alert.Vars.all}}`
        subject = {{.Last.Status}}: {{.Alert.Name}}: load(1/5/15): ({{.Eval .Alert.Vars.load1_avg | printf "%.2f" }}/{{.Eval .Alert.Vars.load5_avg | printf "%.2f" }}/{{.Eval .Alert.Vars.load15_avg | printf "%.2f" }}) CPUS: {{.Eval .Alert.Vars.cpus}} on {{.Group.host}}
}

template name {
        body = Name: {{.Alert.Name}}
}

template ex {
        body = `Alert definition:
        {{template "name" .}}
        Crit: {{.Alert.Crit}}

        Tags:{{range $k, $v := .Group}}
        {{$k}}: {{$v}}{{end}}
        {{.Graph .Alert.Vars.metric}}
        `
        subject = {{.Alert.Name}}: {{.Eval .Alert.Vars.q }} on {{.Group.host}}
}

##############
# mem_checks #
##############

alert unix.memory {
    template = ex
    $metric = q("sum:mem_used_percent{host=*}", "1h", "")
    $q = avg($metric)
    crit = $q > 99
    warn = $q > 98
    warnNotification = default
    critNotification = default
}

#alert elastic.memory {
#    template = ex
#    $metric = q("sum:elasticsearch_jvm_mem_heap_used_percent{host=*}", "30m", "")
#    $q      = avg($metric)
#    crit = $q > 95
#    warn = $q > 90
#    warnNotification = default
#    critNotification = default
#}

###############
# load checks #
###############

alert unix.load {
    #squelch = host=node*
    template  = load
    $time     = 30m
    $cpucount = q("sum:system_n_cpus{host=*}", "$time", "")
    $cpus     = avg($cpucount)
    $load1  = q("sum:system_load1{host=*}",  "$time", "")
    $load5  = q("sum:system_load5{host=*}",  "$time", "")
    $load15 = q("sum:system_load15{host=*}", "$time", "")
    $load1_avg  = avg($load1)
    $load5_avg  = avg($load5)
    $load15_avg = avg($load15)
    $all = merge(rename($load1, "host=short"), rename($load5, "host=middle"), rename($load15, "host=long"), rename($cpucount, "host=cpus"))
    crit = $load1_avg > ($cpus * 1.4) || $load5_avg > ($cpus * 1.3) || $load15_avg > ($cpus * 1.2)
    warn = $load1_avg > ($cpus * 1.3) || $load5_avg > ($cpus * 1.2) || $load15_avg > ($cpus * 1.1)
    warnNotification = default
    critNotification = default
}

#################
# disk forecast #
#################
template header {
    body = `<p><a href="{{.Ack}}">Acknowledge alert</a>
    <p><a href="{{.Rule}}">View the Rule + Template in the Bosun's Rule Page</a>
    {{if .Alert.Vars.notes}}
    <p>Notes: {{.Alert.Vars.notes}}
    {{end}}
    {{if .Group.host}}
    <p><a href="https://gevisfrontpat.eb.lan.at/dashboard/node?node={{.Group.host}}">View Host {{.Group.host}} in Opserver</a>
    {{end}}
    `
}

template diskspace {
    body = `{{template "header" .}}
    <p>Host: <a href="{{.HostView .Group.host | short }}">{{.Group.host}}</a>
    <br>Disk: {{.Group.path}}

    <p>Percent Free: {{.Eval .Alert.Vars.percent_free | printf "%.2f"}}%
    <br>Used: {{.Eval .Alert.Vars.used | bytes}}
    <br>Total: {{.Eval .Alert.Vars.total | bytes}}
    <br>Est. {{.Eval .Alert.Vars.days_to_zero | printf "%.2f"}} days remain until 0% free space
    {{/* .Graph .Alert.Vars.percent_free_graph */}}
    {{printf "(100 - q(\"avg:1h-min:disk_used_percent{host=%s,path=%s}\", \"14d\", \"\"))" .Group.host .Group.path | .Graph}}
    `
    subject = {{.Last.Status}}: Diskspace: ({{.Alert.Vars.used | .Eval | bytes}}/{{.Alert.Vars.total | .Eval | bytes}}) {{.Alert.Vars.percent_free | .Eval | printf "%.2f"}}% Free on {{.Group.host}}:{{.Group.path}} (Est. {{.Eval .Alert.Vars.days_to_zero | printf "%.2f"}} days remain)
}

lookup disk_space {
    entry host=*,path=*,fstype=* {
        warn_percent_free = 10
        crit_percent_free = 5
    }
}

alert unix.forecast_diskspace {
    template = diskspace
    $filter = host=*,path=*,fstype=literal_or(zfs|ext4)

    $days_to_zero = (forecastlr(q("avg:6h-avg:disk_used_percent{$filter}", "14d", ""), 100) / 60 / 60 / 24)
    $warn_days = $days_to_zero > 0 && $days_to_zero < 4
    $crit_days =   $days_to_zero > 0 && $days_to_zero < 3

    ##Percent Free Section
    $pf_time = "5m"
    $percent_free = (100 - avg(q("avg:disk_used_percent{$filter}", $pf_time, "")))
    $used = avg(q("avg:disk_used{$filter}", $pf_time, ""))
    $total = avg(q("avg:disk_total{$filter}", $pf_time, ""))
    $warn_percent = $percent_free <  lookup("disk_space", "warn_percent_free")
    #Linux stops root from writing at less than 5%
    $crit_percent = $percent_free <  lookup("disk_space", "crit_percent_free")
    #For graph (long time)
    $percent_free_graph = q("avg:1h-min:disk_used_percent{$filter}", "14d", "")

    runEvery = 3
    ##Main Logic
    warn = $warn_percent || $warn_days
    crit = $crit_percent || $crit_days
    ##Options
    ignoreUnknown = true
    #This is needed because disks go away when the forecast doesn't
    unjoinedOk = true
    warnNotification = default
    critNotification = default
}

template haproxy {
        body = `<a href="{{.Ack}}">Acknowledge alert</a>
        <p>Alert definition:
        <p>Name: {{.Alert.Name}}
        <p>Crit: {{.Alert.Crit}}
        <p>Tags
        <table>
                {{range $k, $v := .Group}}
                        {{if eq $k "host"}}
                                <tr><td>{{$k}}:</td><td><a href="{{$.HostView $v}}">{{$v}}</a></td></tr>
                        {{else}}
                                <tr><td>{{$k}}:</td><td>{{$v}}</td></tr>
                        {{end}}
                {{end}}
        </table>

        </br>
        <p>scur {{.Eval .Alert.Vars.current_sessions | printf "%.0f"}}</p>
        <p>slim {{.Eval .Alert.Vars.session_limit | printf "%.0f"}}</p>
        </br>
        {{.Graph .Alert.Vars.all}}`
        subject = {{.Last.Status}}: {{.Alert.Name}} on {{.Group.host}} sessions: {{.Eval .Alert.Vars.current_sessions | printf "%.0f" }} from  {{.Eval .Alert.Vars.session_limit | printf "%.0f" }} used
        inherit = mattermost
}

alert haproxy.session_limit {
    template = haproxy
    $current_sessions = max(q("sum:haproxy_scur{host=*,proxy=*,type=frontend}", "5m", ""))
    $session_limit = max(q("sum:haproxy_slim{host=*,proxy=*,type=frontend}", "5m", ""))
    $current_sessions_metric = q("sum:haproxy_scur{host=*,proxy=*,type=frontend}", "30m", "")
    $session_limit_metric = q("sum:haproxy_slim{host=*,proxy=*,type=frontend}", "30m", "")
    $all = merge(rename($current_sessions_metric, "host=current"), rename($session_limit_metric, "host=limit"))
    $q = ($current_sessions / $session_limit) * 100
    warn = $q > 80
    crit = $q > 95
    warnNotification = default
    critNotification = default
}

### check elastic datanodes

#alert elastic.datanodes {
#    template = generic
#    $q = min(q("sum:elasticsearch_clusterstats_nodes_count_data{host=*}", "5m", ""))
#    crit = $q < 1
#    critNotification = default
#    warnNotification = default
#}

### check elastic masternodes

#alert elastic.masternodes {
#    template = generic
#    $q = min(q("sum:elasticsearch_clusterstats_nodes_count_master{host=*}", "5m", ""))
#    crit = $q < 1
#    critNotification = default
#    warnNotification = default
#}

### check rtm_mics per ident ####
#alert weblog.rtm {
#    template = weblog.rtm
#    $index = esindices("@timestamp","logstash-alias")
#    $filter=esall()
#    $q=esstat($index, "ident.keyword", $filter,"rtm_mics", "avg", "15m", "30m", "")
#    $p50=(percentile($q, .50) / 1000000)
#    warn = $p50 > 4
#    crit = $p50 > 5
#    ignoreUnknown = true
#    squelch = ident.keyword=login.preprod.erste-group.net
#    critNotification = default,thomas,leibrecht
#    warnNotification = default,thomas,leibrecht
#}

template api.sparkasse.at.response.5xx {
        body = `<a href="{{.Ack}}">Acknowledge alert</a>
        <p>Alert definition:
        <p>Name: {{.Alert.Name}}
        <p>Crit: {{.Alert.Crit}}
        <p>Tags
        <table>
                {{range $k, $v := .Group}}
                        {{if eq $k "host"}}
                                <tr><td>{{$k}}</td><td><a href="{{$.HostView $v}}">{{$v}}</a></td></tr>
                        {{else}}
                                <tr><td>{{$k}}</td><td>{{$v}}</td></tr>
                        {{end}}
                {{end}}
        </table>

        <p>Computation
        <table>
                {{range .Computations}}
                        <tr><td>{{.Text}}:</td><td>{{.Value}}</td></tr>
                {{end}}
        </table>
        </br>
        {{.Graph .Alert.Vars.graph}}`
        subject = {{.Last.Status}}: {{.Alert.Name}}: {{.Eval .Alert.Vars.qmax}} on api.sparkasse.at
        inherit = mattermost
}

#alert api.sparkasse.at.response.5xx {
#    template = api.sparkasse.at.response.5xx
#    $index = esindices("@timestamp","logstash-alias")
#    $filter=esand(esquery("ident", "api.sparkasse.at"), esquery("response","[500 TO 599]"))
#    $q=escount($index, "ident.keyword", $filter, "1m", "30m", "")
#    $graph=escount($index, "response.keyword", $filter, "1m", "30m", "")
#    $qmax=max($q)
#    ignoreUnknown = true
#    crit = $qmax > 1000
#    critNotification = default,thomas,MLDevOpsGeorgeATsIT,leibrecht,mattermost
#}

############################
# logstash "cluster" check #
############################

template logstash.cpu_usage_idle {
    body = `<a href="{{.Ack}}">Acknowledge alert</a>
    <br>
    <br>
    <b>Cpu idle by host:</b>
    <table>
    {{range $f := .EvalAll .Alert.Vars.idle_by_host}}
        <tr><td>{{ $f.Group.host }} {{ $f.Group.cpu }}:</td>
        {{if lt $f.Value 20.0}}
            <td style="color: red;">
            {{else}}
                <td style="color: green;">
            {{end}}
        {{ $f.Value | printf "%.0f" }}</td></tr>
    {{end}}
    <tr><td><b>Total:</b></td><td>{{.Eval .Alert.Vars.idle_total | printf "%.0f" }}</td></tr>
    </table>
    <br>
    {{.Graph .Alert.Vars.idle_series_by_host_historical}}
`
    subject = {{.Last.Status}}: {{.Alert.Name}} : {{.Eval .Alert.Vars.idle_total | printf "%.0f"}}% cpu idle in cluster. {{.Eval .Alert.Vars.num_hosts_low}} of {{.Eval .Alert.Vars.num_hosts}} hosts have insufficient cpu idle
    inherit = mattermost
}


alert pine.cpu_usage_idle {
    template = logstash.cpu_usage_idle
    $group = host=wildcard(pine*)
    $idle_series_by_host = q("sum:cpu_usage_idle{cpu=wildcard(*),$group}{cpu=not_literal_or(cpu-total)}", "5m", "")
    $idle_series_by_host_historical = q("sum:cpu_usage_idle{cpu=wildcard(*),$group}{cpu=not_literal_or(cpu-total)}", "5m", "")
    $idle_by_host = avg($idle_series_by_host)
    $num_hosts = len(t($idle_by_host, "cpu"))
    $idle_total= sum(t($idle_by_host, "cpu"))

    $hosts_low = t($idle_by_host < 20, "cpu")
    $num_hosts_low = sum($hosts_low)
    $ratio_hosts_low = ($num_hosts_low / $num_hosts)

    warn = ($ratio_hosts_low > 0.7) || ($idle_total < 80)
    crit = ($ratio_hosts_low > 0.8) || ($idle_total < 40)
    warnNotification = default
    critNotification = default
}

alert tsdb.added_points {
    $tpl_desc = "datapoints added per node this rate should not drop"
    $q_duration = "1h"
    $q_metric = "sum:rate{counter,,1}:tsd.datapoints.added{class=*,host=data*,type=*}"
    $q_period = "1h"
    $q_lookback = 6
    $g_std_warn = 50
    $g_std_crit = 100
    template = anomaly
    macro = anomaly
    ignoreUnknown = true
    unjoinedOk = true
    critNotification = default
    warnNotification = default
}

template anomaly {
        body = `<a href="{{.Ack}}">Acknowledge alert</a>
        <p>Alert definition:
        <p>Name: {{.Alert.Name}}
        <p>Crit: {{.Alert.Crit}}
        <p>Tags
        <table>
                {{range $k, $v := .Group}}
                        {{if eq $k "host"}}
                                <tr><td>{{$k}}</td><td><a href="{{$.HostView $v}}">{{$v}}</a></td></tr>
                        {{else}}
                                <tr><td>{{$k}}</td><td>{{$v}}</td></tr>
                        {{end}}
                {{end}}
        </table>

        <p>Computation
        <table>
                {{range .Computations}}
                        <tr><td>{{.Text}}</td><td>{{.Value}}</td></tr>
                {{end}}
        </table>
        </br>
        {{.Graph .Alert.Vars.graph}}`
        subject = {{.Last.Status}}: {{.Alert.Name}}: {{.Eval .Alert.Vars.s_current_median | printf "%.2f"}} (then: {{.Eval .Alert.Vars.s_hist_median | printf "%.2f"}}) on {{.Group.host}}
        inherit = mattermost
}

alert elastic.index_events {
    $tpl_desc = "events indexed over all elastic nodes this rate should not drop"
    $q_duration = "1h"
    $q_metric = "sum:rate:elasticsearch_indices_indexing_index_total{host=wildcard(*)}"
    $q_period = "7d"
    $q_lookback = 4
    $g_std_warn = 900
    $g_std_crit = 1200
    template = anomaly
    macro = anomaly
    ignoreUnknown = true
    unjoinedOk = true
    critNotification = default
    warnNotification = default
}


template elastic.index_time {
        body = `<a href="{{.Ack}}">Acknowledge alert</a>
        <p>Alert definition:
        <p>Name: {{.Alert.Name}}
        <p>Crit: {{.Alert.Crit}}
        <p>Tags
        <table>
                {{range $k, $v := .Group}}
                        {{if eq $k "host"}}
                                <tr><td>{{$k}}</td><td><a href="{{$.HostView $v}}">{{$v}}</a></td></tr>
                        {{else}}
                                <tr><td>{{$k}}</td><td>{{$v}}</td></tr>
                        {{end}}
                {{end}}
        </table>

        <p>Computation
        <table>
                {{range .Computations}}
                        <tr><td>{{.Text}}</td><td>{{.Value}}</td></tr>
                {{end}}
        </table>
        </br>
        {{.Graph .Alert.Vars.graph}}`
        subject = {{.Last.Status}}: {{.Alert.Name}}: indexing time is {{.Eval .Alert.Vars.s_current_median | printf "%.2f"}}ms (then: {{.Eval .Alert.Vars.s_hist_median | printf "%.2f"}}ms) on {{.Group.host}}
    inherit = mattermost
}

alert elastic.index_time {
    $tpl_desc = "index time over all elastic nodes this rate should not rise"
    $q_duration = "1h"
    $q_metric = "sum:rate:elasticsearch_indices_indexing_index_time_in_millis{host=wildcard(*)}"
    $q_period = "7d"
    $q_lookback = 4
    $g_std_warn = 200
    $g_std_crit = 300
    template = elastic.index_time
    macro = anomaly.inverted
    ignoreUnknown = true
    unjoinedOk = true
    critNotification = default
    warnNotification = default
}

################
# cisco checks #
################

alert cisco.load {
	template = ex
	$metric_short  = avg(q("sum:snmp_cpmCPUTotal5sec{host=*}", "120m", ""))
	$metric_middle = avg(q("sum:snmp_cpmCPUTotal1min{host=*}", "120m", ""))
	$metric_long   = avg(q("sum:snmp_cpmCPUTotal5min{host=*}", "120m", ""))
	crit = $metric_short > 85 || $metric_middle > 80 || $metric_long > 75
	warn = $metric_short > 80 || $metric_middle > 75 || $metric_long > 70
    warnNotification = default
    critNotification = default
}

############
# hardware #
############

template hardware {
    body = `
    <style>
    table {
        border-collapse: collapse;
    }
    th,td {
        text-align: left;
        padding-right: 8px;
    }
    </style>
    <p>Overall System status is  {{if gt .Value 1.0}} <span style="color: red;">Bad</span>
              {{else}} <span style="color: green;">Ok</span>
              {{end}}</p>
    
    <h3>Power Supplies</h3>
    <table>
    <tr><th>Power Supply Name:</th><th>Status:</th><th>Watt:</th></tr>
    {{ range $r := .LeftJoin .Alert.Vars.power .Alert.Vars.power_val }}
    	{{ $power     := index $r 0 }}
		{{ $power_val := index $r 1 }}
            <tr>
              <td>{{$power.Group.name}}</td>
              {{if lt $power.Value 1.0}} <td style="color: red;">Bad</td>
              {{else}} <td style="color: green;">Ok</td>
              {{end}}
              <td>{{$power_val.Value}}</td>
            </tr>
    {{end}}
    </table>
    
    <h3>Fan Blocks</h3>
    <table>
    <tr><th>Fan Blocks Name</th><th>Status</th></tr>
    {{range $r := .EvalAll .Alert.Vars.fanblocks}}
        {{if eq $r.Group.host $.Group.host}}
            <tr>
              <td>{{$r.Group.name}}</td>
              {{if lt $r.Value 1.0}} <td style="color: red;">Bad</td>
              {{else}} <td style="color: green;">Ok</td>
              {{end}}
            </tr>
        {{end}}
    {{end}}
    </table>
    
    <h3>Temp Sensors</h3>
    <table>
    <tr><th>Temp Sensor Name</th><th>Status</th><th>Temp:</th></tr>
    {{ range $r := .LeftJoin .Alert.Vars.temp .Alert.Vars.temp_val }}
    	{{ $temp     := index $r 0 }}
		{{ $temp_val := index $r 1 }}
            <tr>
              <td>{{$temp.Group.name}}</td>
              {{if lt $temp.Value 1.0}} <td style="color: red;">Bad</td>
              {{else}} <td style="color: green;">Ok</td>
              {{end}}
              <td>{{$temp_val.Value}}</td>
            </tr>
    {{end}}
    </table>

    <h3>Controller</h3>
    <table>
    <tr><th>Controller Name</th><th>Status</th></tr>
    {{range $r := .EvalAll .Alert.Vars.controllerbay}}
      {{if eq $r.Group.host $.Group.host}}
            <tr>
              <td>{{$r.Group.name}}</td>
              {{if lt $r.Value 1.0}} <td style="color: red;">Bad</td>
              {{else}} <td style="color: green;">Ok</td>
              {{end}}
            </tr>
        {{end}}
    {{end}}
    </table>
    `
    subject = {{.Last.Status}}: {{replace .Alert.Name "." " " -1}}: on {{.Group.host}}
}


#alert hardware.hp {
#    template = hardware
#    $time = "30m"
#    #By Component
#    $power         = avg(q("sum:ipmi_sensor_status{host=*,name=power_supply_*}", $time, ""))
#    $power_val     = avg(q("sum:ipmi_sensor_value{host=*,name=power_supply_*}", $time, ""))
#    $fanblocks     = avg(q("sum:ipmi_sensor_status{host=*,name=fan_block_*}", $time, ""))
#    $temp          = avg(q("sum:ipmi_sensor_status{host=*,name=temp_*}", $time, ""))
#    $temp_val      = avg(q("sum:ipmi_sensor_value{host=*,name=temp_*}", $time, ""))
#    $controllerbay = avg(q("sum:ipmi_sensor_status{host=*,name=cntlr_*}", $time, ""))
#    $system        = avg(q("sum:ipmi_sensor_status{host=*,name=*}", $time, ""))
#    #Component Summary Per Host
#    $s_power= sum(t($power, "host"))
#    $s_fanblocks = sum(t($fanblocks, "host"))
#    
#    warn = $system < 1
#}

# This macro isn't Show, but makes it so IT and SRE are notified for their
#respective systems, when an alert is host based.

lookup linux_tcp {
	entry host=ny-tsdb03 {
		backlog_drop_threshold = 500
	}
	entry host=* {
		backlog_drop_threshold = 100
	}
}

template linux.tcp {
	body = `
		{{template "header" .}}
		<table>
			{{/* TODO: Reference what each stat means */}}
			<tr><th>Stat</th><th>Count in the last {{.Alert.Vars.time}}</th></tr>
			<tr><td>TCP Abort Failed</td><td>{{.Eval .Alert.Vars.abort_failed | printf "%.2f"}}<td></tr>
			<tr><td>Out Of Order Pruned</td><td>{{.Eval .Alert.Vars.ofo_pruned | printf "%.2f"}}<td></tr>
			<tr><td>Receive Pruned</td><td>{{.Eval .Alert.Vars.rcv_pruned | printf "%.2f"}}<td></tr>
			<tr><td>Backlog Dropped</td><td>{{.Eval .Alert.Vars.backlog_drop | printf "%.2f"}}<td></tr>
			<tr><td>Syn Cookies Sent</td><td>{{.Eval .Alert.Vars.syncookies_sent | printf "%.2f"}}<td></tr>
			<tr><td>TOTAL Of Above</td><td>{{.Eval .Alert.Vars.total_err | printf "%.2f"}}<td></tr>
		</table>`
	subject = {{.Last.Status}}: {{.Eval .Alert.Vars.total_err | printf "%.2f"}} tcp errors on {{.Group.host}}
}

alert linux.tcp {
	#macro = host_based
	$notes = `
		This alert checks for various errors or possible issues in the
		TCP stack of a Linux host. Since these tend to happen at the
		same time, combining them into a single alert reduces
		notification noise.`
	template = linux.tcp
	$time = 1h
	$abort_failed = change("sum:rate{counter,,1}:linux.net.stat.tcp.abortfailed{host=*}", "$time", "")
	$abort_mem = change("sum:rate{counter,,1}:linux.net.stat.tcp.abortonmemory{host=*}", "$time", "")
	$ofo_pruned = change("sum:rate{counter,,1}:linux.net.stat.tcp.ofopruned{host=*}", "$time", "")
	$rcv_pruned = change("sum:rate{counter,,1}:linux.net.stat.tcp.rcvpruned{host=*}", "$time", "")
	$backlog_drop = change("sum:rate{counter,,1}:linux.net.stat.tcp.backlogdrop{host=*}", "$time", "")
	$syncookies_sent = change("sum:rate{counter,,1}:linux.net.stat.tcp.syncookiessent{host=*}", "$time", "")
	$total_err = $abort_failed + $ofo_pruned + $rcv_pruned + $backlog_drop + $syncookies_sent
	warn = $abort_failed || $ofo_pruned > 100 || $rcv_pruned > 100 || $backlog_drop > lookup("linux_tcp", "backlog_drop_threshold")  || $syncookies_sent
}

#alert nstat_linux.tcp {
#	#macro = host_based
#	$notes = `
#		This alert checks for various errors or possible issues in the
#		TCP stack of a Linux host. Since these tend to happen at the
#		same time, combining them into a single alert reduces
#		notification noise.`
#	template = linux.tcp
#	$time = 1h
#	$abort_failed = change("sum:rate{counter,,1}:nstat_TcpExtTCPAbortFailed{host=*}", "$time", "")
#	$abort_mem = change("sum:rate{counter,,1}:nstat_TcpExtTCPAbortOnMemory{host=*}", "$time", "")
#	$ofo_pruned = change("sum:rate{counter,,1}:nstat_TcpExtOfoPruned{host=*}", "$time", "")
#	$rcv_pruned = change("sum:rate{counter,,1}:nstat_TcpExtRcvPruned{host=*}", "$time", "")
#	$backlog_drop = change("sum:rate{counter,,1}:nstat_TcpExtTCPBacklogDrop{host=*}", "$time", "")
#	$syncookies_sent = change("sum:rate{counter,,1}:nstat_TcpExtSyncookiesSent{host=*}", "$time", "")
#	$total_err = $abort_failed + $ofo_pruned + $rcv_pruned + $backlog_drop + $syncookies_sent
#	warn = $abort_failed || $ofo_pruned > 100 || $rcv_pruned > 100 || $backlog_drop > lookup("linux_tcp", "backlog_drop_threshold")  || $syncookies_sent
#}