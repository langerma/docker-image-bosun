###################
# my bosun config #
###################

##########
# Macros #
##########

# for series that should not drop
macro anomaly {
    $g_hist = band($q_metric, $q_duration, $q_period, $q_lookback)
    $s_hist_dev = dev($g_hist)
    $s_hist_median = percentile($g_hist, .5)
    $s_current_median = percentile(q($q_metric, $q_duration, ""), .5)
    $s_median_diff = $s_current_median - $s_hist_median
    $graph = over($q_metric, $q_duration, $q_period, $q_lookback)
    warn = $s_current_median > ($s_hist_median + $s_hist_dev*2) && abs($s_median_diff) > $g_std_warn
    crit = $s_current_median > ($s_hist_median + $s_hist_dev*2) && abs($s_median_diff) > $g_std_crit
}

# for series that should not rise
macro anomaly.inverted {
    $g_hist = band($q_metric, $q_duration, $q_period, $q_lookback)
    $s_hist_dev = dev($g_hist)
    $s_hist_median = percentile($g_hist, .5)
    $s_current_median = percentile(q($q_metric, $q_duration, ""), .5)
    $s_median_diff = $s_current_median - $s_hist_median
    $graph = over($q_metric, $q_duration, $q_period, $q_lookback)
    warn = $s_current_median < ($s_hist_median + $s_hist_dev*2) && abs($s_median_diff) > $g_std_warn
    crit = $s_current_median < ($s_hist_median + $s_hist_dev*2) && abs($s_median_diff) > $g_std_crit
}

### NOTE: currently use with caution, it can generate some load
macro anomaly.erratic {
    $g_hist = band($q_metric, $q_duration, $q_period, $q_lookback)
    $s_hist_dev = dev($g_hist)
    $s_hist_median = percentile($g_hist, .5)
    $s_current_median = percentile(q($q_metric, $q_duration, ""), .5)
    $s_median_diff = $s_current_median - $s_hist_median
    $s_erratic = q($q_metric, $q_period, "")
    $s_erratic_dev = (dev($s_erratic) * $s_hist_median) / ( ($s_hist_dev * median($s_erratic)) + 0.01)
    $s_median_diff_dev = ($s_current_median - $s_hist_median)/($s_hist_dev+0.01)
    $s_median_bad = $s_median_diff_dev < $g_min_med_diff
    $s_median_issues = sum(t($s_median_bad,""))
    $graph = over($q_metric, $q_duration, $q_period, $q_lookback)
    warn = ($s_current_median > ($s_hist_median + $s_hist_dev*2) && abs($s_median_diff) > $g_std_warn) || ($s_erratic_dev > $g_max_erratic_warn && $s_median_issues > ($g_max_num_issues_crit / 2))
    crit = ($s_current_median > ($s_hist_median + $s_hist_dev*2) && abs($s_median_diff) > $g_std_crit) || ($s_erratic_dev > $g_max_erratic_crit && $s_median_issues > $g_max_num_issues_crit)
}

#############
# templates #
#############

template mattermost {
  MattermostBody = `payload={"username": "bosun-bot", "text": "{{.Subject}} <{{.Incident}}|view in bosun>"}`
}

template bosun.annotation {
  BosunBody = `{"Id":"","Message":"{{.Last.Status}}: {{.Alert.Name}}: {{.Eval .Alert.Vars.q}} on {{.Group.host}}","StartDate":"","EndDate":"","CreationUser":"bosun","Url":"{{.Ack}}","Source":"{{.Alert.Name}}","Host":"{{.Group.host}}","Owner":"langerma","Category":"{{.Last.Status}}"}`
  BosunBodyAnomaly = `{"Id":"","Message":"{{.Last.Status}}: {{.Alert.Name}}: {{.Eval .Alert.Vars.s_current_median | printf "%.2f"}} (then: {{.Eval .Alert.Vars.s_hist_median | printf "%.2f"}})","StartDate":"","EndDate":"","CreationUser":"bosun","Url":"{{.Ack}}","Source":"{{.Alert.Name}}","Host":"{{.Group.host}}","Owner":"langerma","Category":"{{.Last.Status}}"}`
  BosunBodyElastic = `{"Id":"","Message":"{{.Last.Status}}: {{.Alert.Name}}: {{.Eval .Alert.Vars.qmax}} on {{index .Group "host.name.keyword"}}","StartDate":"","EndDate":"","CreationUser":"bosun","Url":"{{.Ack}}","Source":"{{.Alert.Name}}","Host":"{{index .Group "host.name.keyword"}}","Owner":"langerma","Category":"{{.Last.Status}}"}`
}

notification bosun.annotation {
  post = http://127.0.0.1:8070/api/annotation
  bodyTemplate = BosunBody
  contentType = application/json
}

notification bosun.annotation.anomaly {
  post = http://127.0.0.1:8070/api/annotation
  bodyTemplate = BosunBodyAnomaly
  contentType = application/json
}

notification bosun.annotation.elastic {
  post = http://127.0.0.1:8070/api/annotation
  bodyTemplate = BosunBodyElastic
  contentType = application/json
}

notification mattermost {
  post = http://gevispoc.eb.lan.at/hooks/hh4a9kjpepri383j4s7pn7f9zw
  #select slack body template
  bodyTemplate = MattermostBody
}

notification default {
    email   = langer.markus@gmail.com
    print   = true
    #next    = default
    #timeout = 1d
}

template ut {
    subject = {{.Name}}: {{.Group | len}} unknown alerts
        body = `
            <p>Time: {{.Time}}
            <p>Name: {{.Name}}
            <p>Alerts:
            {{range .Group}}
            <br>{{.}}
    {{end}}`
}

unknownTemplate = ut

template generic {
        body = `<a href="{{.Ack}}">Acknowledge alert</a>
        <p>Alert definition:
        <p>Name: {{.Alert.Name}}
        <p>Crit: {{.Alert.Crit}}
        <p>Description: {{.Alert.Vars.alertDescr}}
        <p>Tags
        <table>
                {{range $k, $v := .Group}}
                        {{if eq $k "host"}}
                                <tr><td>{{$k}}</td><td><a href="{{$.HostView $v}}">{{$v}}</a></td></tr>
                        {{else}}
                                <tr><td>{{$k}}</td><td>{{$v}}</td></tr>
                        {{end}}
                {{end}}
        </table>

        <p>Computation
        <table>
                {{range .Computations}}
                        <tr><td>{{.Text}}</td><td>{{.Value}}</td></tr>
                {{end}}
        </table>
        </br>
        {{.Graph .Alert.Vars.metric}}`
        subject = {{.Last.Status}}: {{.Alert.Name}}: {{.Eval .Alert.Vars.q}} on {{.Group.host}}
        inherit = bosun.annotation
}

template weblog.rtm {
        body = `<a href="{{.Ack}}">Acknowledge alert</a>
        <p>Alert definition:
        <p>Name: {{.Alert.Name}}
        <p>Crit: {{.Alert.Crit}}
        <p>Tags
        <table>
                {{range $k, $v := .Group}}
                        {{if eq $k "host"}}
                                <tr><td>{{$k}} :</td><td><a href="{{$.HostView $v}}">{{$v}}</a></td></tr>
                        {{else}}
                                <tr><td>{{$k}} :</td><td>{{$v}}</td></tr>
                        {{end}}
                {{end}}
        </table>
        <br />
        <table>
                        <tr><th>Expression</th><th>Value</th></tr>
                {{range .Computations}}
                        <tr><td>{{.Text}} :</td><td>{{.Value}}</td></tr>
                {{end}}
        </table>
        </br>`
        subject = {{.Last.Status}}: {{.Alert.Name}}: {{.Eval .Alert.Vars.p50}} on {{index .Group "ident.keyword"}}
}

template load {
        body = `<a href="{{.Ack}}">Acknowledge alert</a>
        <p>Alert definition:
        <p>Name: {{.Alert.Name}}
        <p>Crit: {{.Alert.Crit}}
        <p>Tags
        <table>
                {{range $k, $v := .Group}}
                        {{if eq $k "host"}}
                                <tr><td>{{$k}}</td><td><a href="{{$.HostView $v}}">{{$v}}</a></td></tr>
                        {{else}}
                                <tr><td>{{$k}}</td><td>{{$v}}</td></tr>
                        {{end}}
                {{end}}
        </table>

        <p>Computation
        <table>
                        <tr><th>Expression :</th><th>Value :</th></tr>
                {{range .Computations}}
                        <tr><td>{{.Text}}</td><td>{{.Value}}</td></tr>
                {{end}}
        </table>
        </br>
        {{.Graph .Alert.Vars.all}}`
        subject = {{.Last.Status}}: {{.Alert.Name}}: load(1/5/15): ({{.Eval .Alert.Vars.load1_avg | printf "%.2f" }}/{{.Eval .Alert.Vars.load5_avg | printf "%.2f" }}/{{.Eval .Alert.Vars.load15_avg | printf "%.2f" }}) CPUS: {{.Eval .Alert.Vars.cpus}} on {{.Group.host}}
}

template name {
        body = Name: {{.Alert.Name}}
}

template ex {
        body = `Alert definition:
        {{template "name" .}}
        Crit: {{.Alert.Crit}}

        Tags:{{range $k, $v := .Group}}
        {{$k}}: {{$v}}{{end}}
        {{.Graph .Alert.Vars.metric}}
        `
        subject = {{.Alert.Name}}: {{.Eval .Alert.Vars.q }} on {{.Group.host}}
        inherit = bosun.annotation
}



##############
# mem_checks #
##############

alert unix.memory {
    template = generic
    $metric = q("sum:mem_used_percent{host=*}", "5m", "")
    $q = avg($metric)
    crit = $q > 99.5
    warn = $q > 98
    runEvery = 300
    ignoreUnknown = true
    warnNotification = default,bosun.annotation
    critNotification = default,bosun.annotation
}

################
# bsd upgrades #
################

alert bsd.pkg.security {
    template = ex
    $metric = q("sum:pkg_nagios_value{host=*,perfdata=security_problems,unit=i}", "5m", "")
    $q = max($metric)
    crit = $q > 1
    warn = $q > 0
    #ignoreUnknown = true
    unknown = 5m
    warnNotification = default,bosun.annotation
    critNotification = default,bosun.annotation
}

alert bsd.pkg.update {
    template = ex
    $metric = q("sum:pkg_nagios_value{host=*,perfdata=total_updates,unit=i}", "5m", "")
    $q = max($metric)
    crit = $q > 8
    warn = $q > 5
    #ignoreUnknown = true
    unknown = 5m
    warnNotification = default,bosun.annotation
    critNotification = default,bosun.annotation
}

######################
# connectivity check #
######################

alert ping.packet_loss {
    template = ex
    $metric = q("sum:ping_percent_packet_loss{host=*}", "5m", "")
    $q = avg($metric)
    crit = $q > 9
    warn = $q > 8
    unknown = 5m
    warnNotification = default,bosun.annotation
    critNotification = default,bosun.annotation
}

alert ping.average_response {
    template = ex
    $metric = q("sum:ping_average_response_ms{host=*}", "10m", "")
    $q = avg($metric)
    crit = $q > 80
    warn = $q > 75
    unknown = 5m
    warnNotification = default,bosun.annotation
    critNotification = default,bosun.annotation
}


alert elastic.memory {
    template = ex
    $metric = q("sum:elasticsearch_jvm_mem_heap_used_percent{host=*}", "30m", "")
    $q      = avg($metric)
    crit = $q > 95
    warn = $q > 90
    unknown = 5m
    warnNotification = default,bosun.annotation
    critNotification = default,bosun.annotation
}

###############
# load checks #
###############

#alert unix.load {
#    #squelch = host=node*
#    template  = load
#    $time     = 30m
#    $cpucount = q("sum:system_n_cpus{host=*}", "$time", "")
#    $cpus     = avg($cpucount)
#    $load1  = q("sum:system_load1{host=*}",  "$time", "")
#    $load5  = q("sum:system_load5{host=*}",  "$time", "")
#    $load15 = q("sum:system_load15{host=*}", "$time", "")
#    $load1_avg  = avg($load1)
#    $load5_avg  = avg($load5)
#    $load15_avg = avg($load15)
#    $all = merge(rename($load1, "host=short"), rename($load5, "host=middle"), rename($load15, "host=long"), rename($cpucount, "host=cpus"))
#    crit = $load1_avg > ($cpus * 1.4) || $load5_avg > ($cpus * 1.3) || $load15_avg > ($cpus * 1.2)
#    warn = $load1_avg > ($cpus * 1.3) || $load5_avg > ($cpus * 1.2) || $load15_avg > ($cpus * 1.1)
#    warnNotification = default
#    critNotification = default
#}

alert os.cpu.low {
    $time = 5m
    ignoreUnknown = true
    $alertDescr = cpu is low, as idle is low\n
    $metric = q("sum:cpu_usage_idle{host=*,cpu=cpu-total}", "$time", "")
    $q = avg($metric)
    $crit_value = 5
    $warn_value = 10
    warn = $q < $warn_value
    crit = $q <= $crit_value
    template = generic
    unknown = 5m
    critNotification = default,bosun.annotation
    warnNotification = default,bosun.annotation
}

alert os.disk.io_time {
    $time = 5m
    ignoreUnknown = true
    $alertDescr = disk io_time is the time spent waiting on a disk; when this is nearing 10k it means that we are spending 100% time waiting.\nThis is because the time between polling io_time is 10 seconds, or 10k milliseconds
    $metric = q("sum:rate{counter,,1}:diskio_io_time{host=*,name=*}","$time", "")
    $q = avg($metric)
    $crit_value = 8000
    $warn_value = 7000
    warn = $q > $warn_value
    crit = $q >= $crit_value
    template = generic
    unknown = 5m
    critNotification = default,bosun.annotation
    warnNotification = default,bosun.annotation
}

#################
# disk forecast #
#################
template header {
    body = `<p><a href="{{.Ack}}">Acknowledge alert</a>
    <p><a href="{{.Rule}}">View the Rule + Template in the Bosun's Rule Page</a>
    {{if .Alert.Vars.notes}}
    <p>Notes: {{.Alert.Vars.notes}}
    {{end}}
    {{if .Group.host}}
    <p><a href="https://gevisfrontpat.eb.lan.at/dashboard/node?node={{.Group.host}}">View Host {{.Group.host}} in Opserver</a>
    {{end}}
    `
}

template diskspace {
    body = `{{template "header" .}}
    <p>Host: <a href="{{.HostView .Group.host | short }}">{{.Group.host}}</a>
    <br>Disk: {{.Group.path}}

    <p>Percent Free: {{.Eval .Alert.Vars.percent_free | printf "%.2f"}}%
    <br>Used: {{.Eval .Alert.Vars.used | bytes}}
    <br>Total: {{.Eval .Alert.Vars.total | bytes}}
    <br>Est. {{.Eval .Alert.Vars.days_to_zero | printf "%.2f"}} days remain until 0% free space
    {{/* .Graph .Alert.Vars.percent_free_graph */}}
    {{printf "(100 - q(\"avg:1h-min:disk_used_percent{host=%s,path=%s}\", \"14d\", \"\"))" .Group.host .Group.path | .Graph}}
    `
    subject = {{.Last.Status}}: Diskspace: ({{.Alert.Vars.used | .Eval | bytes}}/{{.Alert.Vars.total | .Eval | bytes}}) {{.Alert.Vars.percent_free | .Eval | printf "%.2f"}}% Free on {{.Group.host}}:{{.Group.path}} (Est. {{.Eval .Alert.Vars.days_to_zero | printf "%.2f"}} days remain)
}

lookup disk_space {
    entry host=*,path=*,fstype=* {
        warn_percent_free = 5
        crit_percent_free = 2
    }
}

alert unix.forecast_diskspace {
    template = diskspace
    $filter = host=*,path=*,fstype=literal_or(zfs|ext4|xfs)

    $days_to_zero = (forecastlr(q("avg:6h-avg:disk_used_percent{$filter}", "14d", ""), 100) / 60 / 60 / 24)
    $warn_days = $days_to_zero > 0 && $days_to_zero < 3
    $crit_days =   $days_to_zero > 0 && $days_to_zero < 2

    ##Percent Free Section
    $pf_time = "5m"
    $percent_free = (100 - avg(q("avg:disk_used_percent{$filter}", $pf_time, "")))
    $used = avg(q("avg:disk_used{$filter}", $pf_time, ""))
    $total = avg(q("avg:disk_total{$filter}", $pf_time, ""))
    $warn_percent = $percent_free <  lookup("disk_space", "warn_percent_free")
    #Linux stops root from writing at less than 5%
    $crit_percent = $percent_free <  lookup("disk_space", "crit_percent_free")
    #For graph (long time)
    $percent_free_graph = q("avg:1h-min:disk_used_percent{$filter}", "14d", "")

    runEvery = 60
    ##Main Logic
    warn = $warn_percent || $warn_days
    crit = $crit_percent || $crit_days
    ##Options
    ignoreUnknown = true
    #This is needed because disks go away when the forecast doesn't
    unjoinedOk = true
    #unknown = 5m
    warnNotification = default
    critNotification = default
}

template haproxy {
        body = `<a href="{{.Ack}}">Acknowledge alert</a>
        <p>Alert definition:
        <p>Name: {{.Alert.Name}}
        <p>Crit: {{.Alert.Crit}}
        <p>Tags
        <table>
                {{range $k, $v := .Group}}
                        {{if eq $k "host"}}
                                <tr><td>{{$k}}:</td><td><a href="{{$.HostView $v}}">{{$v}}</a></td></tr>
                        {{else}}
                                <tr><td>{{$k}}:</td><td>{{$v}}</td></tr>
                        {{end}}
                {{end}}
        </table>

        </br>
        <p>scur {{.Eval .Alert.Vars.current_sessions | printf "%.0f"}}</p>
        <p>slim {{.Eval .Alert.Vars.session_limit | printf "%.0f"}}</p>
        </br>
        {{.Graph .Alert.Vars.all}}`
        subject = {{.Last.Status}}: {{.Alert.Name}} on {{.Group.host}} sessions: {{.Eval .Alert.Vars.current_sessions | printf "%.0f" }} from  {{.Eval .Alert.Vars.session_limit | printf "%.0f" }} used
        inherit = bosun.annotation
}

alert haproxy.session_limit {
    template = haproxy
    $current_sessions_metric = q("sum:haproxy_scur{host=*,proxy=*,type=frontend}", "10m", "")
    $session_limit_metric = q("sum:haproxy_slim{host=*,proxy=*,type=frontend}", "10m", "")
    $current_sessions = max($current_sessions_metric)
    $session_limit = max($session_limit_metric)
    $all = merge(rename($current_sessions_metric, "host=current"), rename($session_limit_metric, "host=limit"))
    $q = ($current_sessions / $session_limit) * 100
    warn = $q > 90
    crit = $q > 98
    unjoinedOk = true
    ignoreUnknown = true
    unknown = 5m
    warnNotification = default,bosun.annotation
    critNotification = default,bosun.annotation
}

### check elastic datanodes

#alert elastic.datanodes {
#    template = generic
#    $q = min(q("sum:elasticsearch_clusterstats_nodes_count_data{host=*}", "5m", ""))
#    crit = $q < 1
#    critNotification = default
#    warnNotification = default
#}

### check elastic masternodes

#alert elastic.masternodes {
#    template = generic
#    $q = min(q("sum:elasticsearch_clusterstats_nodes_count_master{host=*}", "5m", ""))
#    crit = $q < 1
#    critNotification = default
#    warnNotification = default
#}

### check rtm_mics per ident ####
#alert weblog.rtm {
#    template = weblog.rtm
#    $index = esindices("@timestamp","logstash-alias")
#    $filter=esall()
#    $q=esstat($index, "ident.keyword", $filter,"rtm_mics", "avg", "15m", "30m", "")
#    $p50=(percentile($q, .50) / 1000000)
#    warn = $p50 > 4
#    crit = $p50 > 5
#    ignoreUnknown = true
#    squelch = ident.keyword=login.preprod.erste-group.net
#    critNotification = default,thomas,leibrecht
#    warnNotification = default,thomas,leibrecht
#}

template elastic.error {
        body = `<a href="{{.Ack}}">Acknowledge alert</a>
        <p>Alert definition:
        <p>Name: {{.Alert.Name}}
        <p>Crit: {{.Alert.Crit}}
        <p>Tags
        <table>
                {{range $k, $v := .Group}}
                        {{if eq $k "host"}}
                                <tr><td>{{$k}}:</td><td><a href="{{$.HostView $v}}">{{$v}}</a></td></tr>
                        {{else}}
                                <tr><td>{{$k}}:</td><td>{{$v}}</td></tr>
                        {{end}}
                {{end}}
        </table>

        <p>Computation
        <table>
                {{range .Computations}}
                        <tr><td>{{.Text}}:</td><td>{{.Value}}</td></tr>
                {{end}}
        </table>
        </br>
        {{.Graph .Alert.Vars.graph}}`
        subject = {{.Last.Status}}: {{.Alert.Name}}: {{.Eval .Alert.Vars.qmax}} on {{index .Group "host.name.keyword"}}
        inherit = bosun.annotation
}

#alert api.sparkasse.at.response.5xx {
#    template = api.sparkasse.at.response.5xx
#    $index = esindices("@timestamp","logstash-alias")
#    $filter=esand(esquery("ident", "api.sparkasse.at"), esquery("response","[500 TO 599]"))
#    $q=escount($index, "ident.keyword", $filter, "1m", "30m", "")
#    $graph=escount($index, "response.keyword", $filter, "1m", "30m", "")
#    $qmax=max($q)
#    ignoreUnknown = true
#    crit = $qmax > 1000
#    critNotification = default,thomas,MLDevOpsGeorgeATsIT,leibrecht,mattermost
#}

alert elastic.hbase {
    template = elastic.error
    $index = esmonthly("@timestamp","hbase-","2006.01")
    $filter=esquery("severity", "WARN or ERROR")
    $q=escount($index, "host.name.keyword", $filter, "1m", "15m", "")
    $graph=escount($index, "severity.keyword", $filter, "1m", "15m", "")
    $qmax=max($q)
    #ignoreUnknown = false
    unknownIsNormal = true
    warn = $qmax > 150
    crit = $qmax > 300
    warnNotification = default,bosun.annotation.elastic
    critNotification = default,bosun.annotation.elastic
}

alert elastic.hadoop {
    template = elastic.error
    $index = esmonthly("@timestamp","hadoop-","2006.01")
    $filter=esquery("severity", "WARN or ERROR")
    $q=escount($index, "host.name.keyword", $filter, "1m", "15m", "")
    $graph=escount($index, "severity.keyword", $filter, "1m", "15m", "")
    $qmax=max($q)
    #ignoreUnknown = false
    unknownIsNormal = true
    warn = $qmax > 100
    crit = $qmax > 200
    warnNotification = default,bosun.annotation.elastic
    critNotification = default,bosun.annotation.elastic
}

############################
# logstash "cluster" check #
############################

template logstash.cpu_usage_idle {
    body = `<a href="{{.Ack}}">Acknowledge alert</a>
    <br>
    <br>
    <b>Cpu idle by host:</b>
    <table>
    {{range $f := .EvalAll .Alert.Vars.idle_by_host}}
        <tr><td>{{ $f.Group.host }} {{ $f.Group.cpu }}:</td>
        {{if lt $f.Value 20.0}}
            <td style="color: red;">
            {{else}}
                <td style="color: green;">
            {{end}}
        {{ $f.Value | printf "%.0f" }}</td></tr>
    {{end}}
    <tr><td><b>Total:</b></td><td>{{.Eval .Alert.Vars.idle_total | printf "%.0f" }}</td></tr>
    </table>
    <br>
    {{.Graph .Alert.Vars.idle_series_by_host_historical}}
`
    subject = {{.Last.Status}}: {{.Alert.Name}} : {{.Eval .Alert.Vars.idle_total | printf "%.0f"}}% cpu idle in cluster. {{.Eval .Alert.Vars.num_hosts_low}} of {{.Eval .Alert.Vars.num_hosts}} hosts have insufficient cpu idle
    inherit = mattermost
}

alert tsdb.added_points {
    $tpl_desc = "datapoints added per node this rate should not drop"
    $q_duration = "60m"
    $q_metric = "sum:rate{counter,,1}:tsd.datapoints.added{class=*,host=data*,type=*}"
    $q_period = "1h"
    $q_lookback = 7
    $g_std_warn = 1
    $g_std_crit = 2
    $g_min_med_diff = 1
    $g_max_erratic_warn = 1.2
    $g_max_erratic_crit = 1.3
    $g_max_num_issues_crit = 30
    template = anomaly
    macro = anomaly.erratic
    runEvery = 30
    ignoreUnknown = true
    unjoinedOk = true
    #unknown = 5m
    critNotification = bosun.annotation.anomaly
    warnNotification = bosun.annotation.anomaly
}

alert environment.temperature {
    $time = 30m
    #ignoreUnknown = true
    $alertDescr =  if temp is to high or to low\n
    $t1 = q("sum:sensehat_exec_temperature_humidity{host=*}{}", "$time", "")
    $t2 = q("sum:sensehat_exec_temperature_pressure{host=*}{}", "$time", "")
    $t_cpu = avg(q("sum:sensehat_exec_temperature_cpu{host=*}{}", "$time", ""))
    $t = (($t1 + $t2) / 2)
    $t_corr = $t - (($t_cpu - $t)/1.2)
    $metric_simple = $t_corr
    $q = avg($metric_simple)
    $crit_high_value = 30
    $warn_high_value = 28
    $crit_low_value = 18
    $warn_low_value = 20
    warn = $q > $warn_high_value || $q < $warn_low_value
    crit = $q >= $crit_high_value || $q <= $crit_low_value
    $now = epoch()
    $Ago =  $now-d("$time")
    $metric = merge(series("warn_low=$warn_low_value", $Ago, $warn_low_value, $now, $warn_low_value), series("warn_high=$warn_high_value", $Ago, $warn_high_value, $now, $warn_high_value), series("crit_low=$crit_low_value", $Ago, $crit_low_value, $now, $crit_low_value),series("crit_high=$crit_high_value", $Ago, $crit_high_value, $now, $crit_high_value), $metric_simple)
    template = generic
    unknown = 5m
    critNotification = default,bosun.annotation
    warnNotification = default,bosun.annotation
}

alert environment.humidity {
    $time = 30m
    #ignoreUnknown = true
    $alertDescr = checks for humidity in livingroom\n
    $metric_simple = q("sum:sensehat_exec_humidity{host=*}", "$time", "")
    $q = avg($metric_simple)
    $crit_low_value = 33
    $warn_low_value = 35
    $crit_high_value = 58
    $warn_high_value = 56
    warn = $q < $warn_low_value || $q > $warn_high_value
    crit = $q <= $crit_low_value || $q >= $crit_high_value
    $now = epoch()
    $Ago =  $now-d("$time")
    $metric = merge(series("warn_low=$warn_low_value", $Ago, $warn_low_value, $now, $warn_low_value), series("warn_high=$warn_high_value", $Ago, $warn_high_value, $now, $warn_high_value), series("crit_low=$crit_low_value", $Ago, $crit_low_value, $now, $crit_low_value),series("crit_high=$crit_high_value", $Ago, $crit_high_value, $now, $crit_high_value), $metric_simple)
    template = generic
    unknown = 5m
    critNotification = default,bosun.annotation
    warnNotification = default,bosun.annotation
}

template anomaly {
        body = `<a href="{{.Ack}}">Acknowledge alert</a>
        <p>Alert definition:
        <p>Name: {{.Alert.Name}}
        <p>Crit: {{.Alert.Crit}}
        <p>Tags
        <table>
                {{range $k, $v := .Group}}
                        {{if eq $k "host"}}
                                <tr><td>{{$k}}</td><td><a href="{{$.HostView $v}}">{{$v}}</a></td></tr>
                        {{else}}
                                <tr><td>{{$k}}</td><td>{{$v}}</td></tr>
                        {{end}}
                {{end}}
        </table>

        <p>Computation
        <table>
            <tr><td>s_hist_dev</td><td>{{.Eval .Alert.Vars.s_hist_dev | printf "%.2f"}}</td></tr>
            <tr><td>s_hist_median</td><td>{{.Eval .Alert.Vars.s_hist_median | printf "%.2f"}}</td></tr>
            <tr><td>s_current_median</td><td>{{.Eval .Alert.Vars.s_current_median | printf "%.2f"}}</td></tr>
            <tr><td>s_median_diff</td><td>{{.Eval .Alert.Vars.s_median_diff | printf "%.2f"}}</td></tr>
            <tr><td>s_erratic_dev</td><td>{{.Eval .Alert.Vars.s_erratic_dev | printf "%.2f"}}</td></tr>
            <tr><td>s_median_diff_dev</td><td>{{.Eval .Alert.Vars.s_median_diff_dev | printf "%.2f"}}</td></tr>
            <tr><td>s_median_bad</td><td>{{.Eval .Alert.Vars.s_median_bad | printf "%.2f"}}</td></tr>
            <tr><td>s_median_issues</td><td>{{.Eval .Alert.Vars.s_median_issues | printf "%.2f"}}</td></tr>
                {{range .Computations}}
                        <tr><td>{{.Text}}</td><td>{{.Value}}</td></tr>
                {{end}}
        </table>
        </br>
        {{.Graph .Alert.Vars.graph}}`
        subject = {{.Last.Status}}: {{.Alert.Name}}: {{.Eval .Alert.Vars.s_current_median | printf "%.2f"}} (then: {{.Eval .Alert.Vars.s_hist_median | printf "%.2f"}}) on {{.Group.host}}
        inherit = bosun.annotation
}

alert elastic.index_events {
    $tpl_desc = "events indexed over all elastic nodes this rate should not drop"
    $q_duration = "1h"
    $q_metric = "sum:rate:elasticsearch_indices_indexing_index_total{host=wildcard(*)}"
    $q_period = "1h"
    $q_lookback = 4
    $g_std_warn = 900
    $g_std_crit = 1200
    template = anomaly
    macro = anomaly
    ignoreUnknown = true
    unjoinedOk = true
    runEvery = 60
    #unknown = 5m
    critNotification = default,bosun.annotation.anomaly
    warnNotification = default,bosun.annotation.anomaly
}


template elastic.index_time {
        body = `<a href="{{.Ack}}">Acknowledge alert</a>
        <p>Alert definition:
        <p>Name: {{.Alert.Name}}
        <p>Crit: {{.Alert.Crit}}
        <p>Tags
        <table>
                {{range $k, $v := .Group}}
                        {{if eq $k "host"}}
                                <tr><td>{{$k}}</td><td><a href="{{$.HostView $v}}">{{$v}}</a></td></tr>
                        {{else}}
                                <tr><td>{{$k}}</td><td>{{$v}}</td></tr>
                        {{end}}
                {{end}}
        </table>

        <p>Computation
        <table>
                {{range .Computations}}
                        <tr><td>{{.Text}}</td><td>{{.Value}}</td></tr>
                {{end}}
        </table>
        </br>
        {{.Graph .Alert.Vars.graph}}`
        subject = {{.Last.Status}}: {{.Alert.Name}}: indexing time is {{.Eval .Alert.Vars.s_current_median | printf "%.2f"}}ms (then: {{.Eval .Alert.Vars.s_hist_median | printf "%.2f"}}ms) on {{.Group.host}}
    inherit = bosun.annotation
}

alert elastic.index_time {
    $tpl_desc = "index time over all elastic nodes this rate should not rise"
    $q_duration = "1h"
    $q_metric = "sum:rate:elasticsearch_indices_indexing_index_time_in_millis{host=wildcard(*)}"
    $q_period = "1h"
    $q_lookback = 4
    $g_std_warn = 200
    $g_std_crit = 300
    template = elastic.index_time
    macro = anomaly.inverted
    ignoreUnknown = true
    unjoinedOk = true
    runEvery = 60
    #unknown = 5m
    critNotification = default,bosun.annotation.anomaly
    warnNotification = default,bosun.annotation.anomaly
}

################
# cisco checks #
################

#alert cisco.load {
#	template = ex
#	$metric_short  = avg(q("sum:snmp_cpmCPUTotal5sec{host=*}", "120m", ""))
#	$metric_middle = avg(q("sum:snmp_cpmCPUTotal1min{host=*}", "120m", ""))
#	$metric_long   = avg(q("sum:snmp_cpmCPUTotal5min{host=*}", "120m", ""))
#	crit = $metric_short > 85 || $metric_middle > 80 || $metric_long > 75
#	warn = $metric_short > 80 || $metric_middle > 75 || $metric_long > 70
#    warnNotification = default
#    critNotification = default
#}

############
# hardware #
############

template hardware {
    body = `
    <style>
    table {
        border-collapse: collapse;
    }
    th,td {
        text-align: left;
        padding-right: 8px;
    }
    </style>
    <p>Overall System status is  {{if gt .Value 1.0}} <span style="color: red;">Bad</span>
              {{else}} <span style="color: green;">Ok</span>
              {{end}}</p>
    
    <h3>Power Supplies</h3>
    <table>
    <tr><th>Power Supply Name:</th><th>Status:</th><th>Watt:</th></tr>
    {{ range $r := .LeftJoin .Alert.Vars.power .Alert.Vars.power_val }}
    	{{ $power     := index $r 0 }}
		{{ $power_val := index $r 1 }}
            <tr>
              <td>{{$power.Group.name}}</td>
              {{if lt $power.Value 1.0}} <td style="color: red;">Bad</td>
              {{else}} <td style="color: green;">Ok</td>
              {{end}}
              <td>{{$power_val.Value}}</td>
            </tr>
    {{end}}
    </table>
    
    <h3>Fan Blocks</h3>
    <table>
    <tr><th>Fan Blocks Name</th><th>Status</th></tr>
    {{range $r := .EvalAll .Alert.Vars.fanblocks}}
        {{if eq $r.Group.host $.Group.host}}
            <tr>
              <td>{{$r.Group.name}}</td>
              {{if lt $r.Value 1.0}} <td style="color: red;">Bad</td>
              {{else}} <td style="color: green;">Ok</td>
              {{end}}
            </tr>
        {{end}}
    {{end}}
    </table>
    
    <h3>Temp Sensors</h3>
    <table>
    <tr><th>Temp Sensor Name</th><th>Status</th><th>Temp:</th></tr>
    {{ range $r := .LeftJoin .Alert.Vars.temp .Alert.Vars.temp_val }}
    	{{ $temp     := index $r 0 }}
		{{ $temp_val := index $r 1 }}
            <tr>
              <td>{{$temp.Group.name}}</td>
              {{if lt $temp.Value 1.0}} <td style="color: red;">Bad</td>
              {{else}} <td style="color: green;">Ok</td>
              {{end}}
              <td>{{$temp_val.Value}}</td>
            </tr>
    {{end}}
    </table>

    <h3>Controller</h3>
    <table>
    <tr><th>Controller Name</th><th>Status</th></tr>
    {{range $r := .EvalAll .Alert.Vars.controllerbay}}
      {{if eq $r.Group.host $.Group.host}}
            <tr>
              <td>{{$r.Group.name}}</td>
              {{if lt $r.Value 1.0}} <td style="color: red;">Bad</td>
              {{else}} <td style="color: green;">Ok</td>
              {{end}}
            </tr>
        {{end}}
    {{end}}
    </table>
    `
    subject = {{.Last.Status}}: {{replace .Alert.Name "." " " -1}}: on {{.Group.host}}
}


#alert hardware.hp {
#    template = hardware
#    $time = "30m"
#    #By Component
#    $power         = avg(q("sum:ipmi_sensor_status{host=*,name=power_supply_*}", $time, ""))
#    $power_val     = avg(q("sum:ipmi_sensor_value{host=*,name=power_supply_*}", $time, ""))
#    $fanblocks     = avg(q("sum:ipmi_sensor_status{host=*,name=fan_block_*}", $time, ""))
#    $temp          = avg(q("sum:ipmi_sensor_status{host=*,name=temp_*}", $time, ""))
#    $temp_val      = avg(q("sum:ipmi_sensor_value{host=*,name=temp_*}", $time, ""))
#    $controllerbay = avg(q("sum:ipmi_sensor_status{host=*,name=cntlr_*}", $time, ""))
#    $system        = avg(q("sum:ipmi_sensor_status{host=*,name=*}", $time, ""))
#    #Component Summary Per Host
#    $s_power= sum(t($power, "host"))
#    $s_fanblocks = sum(t($fanblocks, "host"))
#    
#    warn = $system < 1
#}

# This macro isn't Show, but makes it so IT and SRE are notified for their
#respective systems, when an alert is host based.

lookup linux_tcp {
	entry host=ny-tsdb03 {
		backlog_drop_threshold = 500
	}
	entry host=* {
		backlog_drop_threshold = 100
	}
}

template linux.tcp {
	body = `
		{{template "header" .}}
		<table>
			{{/* TODO: Reference what each stat means */}}
			<tr><th>Stat</th><th>Count in the last {{.Alert.Vars.time}}</th></tr>
			<tr><td>TCP Abort Failed</td><td>{{.Eval .Alert.Vars.abort_failed | printf "%.2f"}}<td></tr>
			<tr><td>Out Of Order Pruned</td><td>{{.Eval .Alert.Vars.ofo_pruned | printf "%.2f"}}<td></tr>
			<tr><td>Receive Pruned</td><td>{{.Eval .Alert.Vars.rcv_pruned | printf "%.2f"}}<td></tr>
			<tr><td>Backlog Dropped</td><td>{{.Eval .Alert.Vars.backlog_drop | printf "%.2f"}}<td></tr>
			<tr><td>Syn Cookies Sent</td><td>{{.Eval .Alert.Vars.syncookies_sent | printf "%.2f"}}<td></tr>
			<tr><td>TOTAL Of Above</td><td>{{.Eval .Alert.Vars.total_err | printf "%.2f"}}<td></tr>
		</table>`
	subject = {{.Last.Status}}: {{.Eval .Alert.Vars.total_err | printf "%.2f"}} tcp errors on {{.Group.host}}
}

#alert linux.tcp {
#	#macro = host_based
#	$notes = `
#		This alert checks for various errors or possible issues in the
#		TCP stack of a Linux host. Since these tend to happen at the
#		same time, combining them into a single alert reduces
#		notification noise.`
#	template = linux.tcp
#	$time = 1h
#	$abort_failed = change("sum:rate{counter,,1}:linux.net.stat.tcp.abortfailed{host=*}", "$time", "")
#	$abort_mem = change("sum:rate{counter,,1}:linux.net.stat.tcp.abortonmemory{host=*}", "$time", "")
#	$ofo_pruned = change("sum:rate{counter,,1}:linux.net.stat.tcp.ofopruned{host=*}", "$time", "")
#	$rcv_pruned = change("sum:rate{counter,,1}:linux.net.stat.tcp.rcvpruned{host=*}", "$time", "")
#	$backlog_drop = change("sum:rate{counter,,1}:linux.net.stat.tcp.backlogdrop{host=*}", "$time", "")
#	$syncookies_sent = change("sum:rate{counter,,1}:linux.net.stat.tcp.syncookiessent{host=*}", "$time", "")
#	$total_err = $abort_failed + $ofo_pruned + $rcv_pruned + $backlog_drop + $syncookies_sent
#	warn = $abort_failed || $ofo_pruned > 100 || $rcv_pruned > 100 || $backlog_drop > lookup("linux_tcp", "backlog_drop_threshold")  || $syncookies_sent
#}

#alert nstat_linux.tcp {
#	#macro = host_based
#	$notes = `
#		This alert checks for various errors or possible issues in the
#		TCP stack of a Linux host. Since these tend to happen at the
#		same time, combining them into a single alert reduces
#		notification noise.`
#	template = linux.tcp
#	$time = 1h
#	$abort_failed = change("sum:rate{counter,,1}:nstat_TcpExtTCPAbortFailed{host=*}", "$time", "")
#	$abort_mem = change("sum:rate{counter,,1}:nstat_TcpExtTCPAbortOnMemory{host=*}", "$time", "")
#	$ofo_pruned = change("sum:rate{counter,,1}:nstat_TcpExtOfoPruned{host=*}", "$time", "")
#	$rcv_pruned = change("sum:rate{counter,,1}:nstat_TcpExtRcvPruned{host=*}", "$time", "")
#	$backlog_drop = change("sum:rate{counter,,1}:nstat_TcpExtTCPBacklogDrop{host=*}", "$time", "")
#	$syncookies_sent = change("sum:rate{counter,,1}:nstat_TcpExtSyncookiesSent{host=*}", "$time", "")
#	$total_err = $abort_failed + $ofo_pruned + $rcv_pruned + $backlog_drop + $syncookies_sent
#	warn = $abort_failed || $ofo_pruned > 100 || $rcv_pruned > 100 || $backlog_drop > lookup("linux_tcp", "backlog_drop_threshold")  || $syncookies_sent
#}
